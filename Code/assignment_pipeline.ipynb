{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cell below if running on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32670,
     "status": "ok",
     "timestamp": 1731187814551,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "xaMa9vovAGxx",
    "outputId": "18839658-18a8-41ef-ea9a-444bf69208d6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# drive.flush_and_unmount()  # Unmount Google Drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create manual prompt for generating write-ups using gpt-4o-mini for each welfare scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5887,
     "status": "ok",
     "timestamp": 1731187821922,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "qpHu48uYAKyX",
    "outputId": "106ffc2e-766c-4c1a-8372-d520edfbcb57"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing the text files\n",
    "directory = \"/content/drive/MyDrive/\" + \"remaining path of welfare scheme txt file\"\n",
    "\n",
    "# Limit to the first 10 files found in the directory (we had 10 schemes)\n",
    "file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".txt\")][:10] \n",
    "\n",
    "# Dictionary to store each file's content\n",
    "file_contents = {}\n",
    "\n",
    "# Read contents of each file\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_contents[file_name] = content\n",
    "\n",
    "# Function to create prompt for each file's content\n",
    "def generate_prompt(file_name, content):\n",
    "    prompt = f\"\"\"The following text describes a welfare scheme. Based on this information, generate the following write-ups for {file_name}.\n",
    "    Retain all relevant information from the original text. No significant details should be omitted. Write-ups should be clear, concise, and easily understandable.\n",
    "\n",
    "Write-up 1: Beneficiary and Problem Statement\n",
    "    Describe who the beneficiary is and the specific problems or challenges they are currently facing.\n",
    "\n",
    "Write-up 2: Application Process and Benefits\n",
    "    Detail the steps required to apply for the scheme and the exact benefits provided upon successful application.\n",
    "\n",
    "Write-up 3: Outcome and Impact\n",
    "    Explain the expected outcomes of the scheme and how it will positively impact the beneficiary's life.\n",
    "\n",
    "Scheme Description:\n",
    "{content}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Generate prompts for each file\n",
    "prompts = {file_name: generate_prompt(file_name, content) for file_name, content in file_contents.items()}\n",
    "\n",
    "# Display prompts for review or use as input to ChatGPT\n",
    "for file_name, prompt in prompts.items():\n",
    "    print(f\"Prompt for {file_name}:\\n{prompt}\\n{'-'*80}\\n\\n\")\n",
    "\n",
    "# Note: After generating the prompts, you would typically pass each prompt to ChatGPT's API for response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3 writeups for each scheme using gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69350,
     "status": "ok",
     "timestamp": 1731174854782,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "8WZJZ5RrAcj8",
    "outputId": "e6681b01-9aed-48b2-fcdc-db109c134b47"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = 'openai_api')\n",
    "\n",
    "output_directory = \"/content/drive/MyDrive/\" + \"remaining path for outputs for LLM write-ups\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for file_name, prompt in prompts.items():\n",
    "    # print(f\"Prompt for {file_name}:\\n{prompt}\\n{'-'*80}\\n\\n\")\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", # Use better model for better quality prompts\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    write_up = completion.choices[0].message.content\n",
    "    # print(completion.choices[0].message.content)\n",
    "\n",
    "    # Save the write-up to a new .txt file in the output directory with the same file name\n",
    "    output_file_path = os.path.join(output_directory, file_name)\n",
    "    with open(output_file_path, 'w+') as output_file:\n",
    "        output_file.write(write_up)\n",
    "\n",
    "    print(f\"Write-up for '{file_name}' saved successfully in '{output_directory}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to generate summary of write-ups using T5 transformer\n",
    "#### (Executing the 2 cells below is not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16358,
     "status": "ok",
     "timestamp": 1731187845126,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "bWbIlawBDqa0",
    "outputId": "c191cf86-4fbf-4fbb-bc3a-5fab35631a68"
   },
   "outputs": [],
   "source": [
    "!pip install transformers nltk\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1382689,
     "status": "ok",
     "timestamp": 1731189329659,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "XTPYO5aan4c0",
    "outputId": "79113be4-faee-4dea-95ac-48046aeac3f9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "input_directory = \"/content/drive/MyDrive/\" + \"remaining path of welfare scheme txt file\"\n",
    "output_directory = \"/content/drive/MyDrive/\" + \"remaining path for outputs for T5 write-ups\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Load T5 Model and Tokenizer\n",
    "model_name = \"t5-base\"  # or \"t5-base\" for a larger model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "for file_name, prompt in prompts.items():\n",
    "    file_path = input_directory + file_name\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "\n",
    "    inputs = tokenizer(f\"Scheme Description: \" + content +\n",
    "                   \"\"\"Based on the above information, please provide a summary of 150 words. Retain all relevant information from the original text. \"\"\",\n",
    "                   return_tensors=\"pt\",\n",
    "                   max_length=2048,\n",
    "                   truncation=True)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=2048, num_beams=8, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    # print(summary)\n",
    "\n",
    "    # Save the write-up to a new .txt file in the output directory with the same file name\n",
    "    output_file_path = os.path.join(output_directory, file_name)\n",
    "    with open(output_file_path, 'w+') as output_file:\n",
    "        output_file.write(summary)\n",
    "\n",
    "    print(f\"Write-up for '{file_name}' saved successfully in '{output_directory}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3 image generation prompts for each welfare scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136783,
     "status": "ok",
     "timestamp": 1731240723521,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "AQN8TgFb67UW",
    "outputId": "41d597a3-2cff-429d-833c-de6a5002f3cd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"openai_api\")\n",
    "\n",
    "output_directory = \"/content/drive/MyDrive/\" + \"remaining path for image prompts\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "directory = \"/content/drive/MyDrive/NLP/\" + \"remaining path for outputs for LLM write-ups\"\n",
    "file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".txt\")]\n",
    "\n",
    "# Initialize the results dictionary\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Remove '.txt' from the file name\n",
    "    scheme_name = file_name.replace(\".txt\", \"\")\n",
    "\n",
    "    prompt1 = f\"\"\"\n",
    "        Generate an image prompt to depict the 'Problem Statement' for the '{scheme_name}' scheme:\\n\\n\"\n",
    "        {content}\\n\\n\n",
    "        Instructions:\\n\n",
    "        - Show the main character (e.g., 'Raju the farmer' or 'Shweta the housewife', etc, whatever is more appropritae) experiencing the challenges described in the scheme's problem statement, such as financial struggles or resource shortages, etc.\\n\n",
    "        - Use a rural or village setting with elements like small farms, simple houses, or crops to illustrate the environment, according to the scheme's objective.\\n\n",
    "        - Focus on conveying the difficulties faced by beneficiaries before receiving support, such as worried expressions, sparse resources, or modest living conditions, etc.\n",
    "        \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt1}\n",
    "        ]\n",
    "    )\n",
    "    img_prompt1 = completion.choices[0].message.content\n",
    "\n",
    "    prompt2 = f\"\"\"\n",
    "        Generate an image prompt to illustrate the 'Application Process' for the '{scheme_name}' scheme:\\n\\n\"\n",
    "        \"{content}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Depict a scene showing the enrollment steps, with the main character (e.g., 'Raju the farmer' or 'Shweta the housewife', etc, whatever is more approprite and mentioned later) at a registration desk or using a digital device.\\n\n",
    "        \"- Highlight the required documents, such as Aadhaar card, bank passbook, or application forms, as visible elements in the scene.\\n\n",
    "        \"- Include a friendly government official or digital interface to emphasize the assistance provided during the application process.\\n\n",
    "        \"- Set the scene in a government office or rural setting, focusing on the action of registration and the accessibility of the process.\n",
    "        Here is the previous image prompt, ensure consistency of characters and story:\n",
    "        {img_prompt1}\n",
    "        \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt2}\n",
    "        ]\n",
    "    )\n",
    "    img_prompt2 = completion.choices[0].message.content\n",
    "\n",
    "    prompt3 = f\"\"\"\n",
    "        Generate an image prompt for the '{scheme_name}' scheme:\\n\\n\"\n",
    "        f\"{content}\\n\\n\"\n",
    "        Instructions:\\n\n",
    "        - Use a rural/appropriate setting and portray characters benefiting from a government support scheme.\n",
    "        - Include symbols of agricultural aid or community support, illustrating the scheme’s purpose.\n",
    "        Here are the previous prompts, ensure consistency of characters and story:\n",
    "        {img_prompt1}\n",
    "        {img_prompt2}\n",
    "        \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt3}\n",
    "        ]\n",
    "    )\n",
    "    img_prompt3 = completion.choices[0].message.content\n",
    "\n",
    "    results.append({\n",
    "        'scheme_name': scheme_name,\n",
    "        'prompt1': img_prompt1,\n",
    "        'prompt2': img_prompt2,\n",
    "        'prompt3': img_prompt3\n",
    "    })\n",
    "\n",
    "    prompt1_path = scheme_name+\"_1.txt\"\n",
    "    prompt2_path = scheme_name+\"_2.txt\"\n",
    "    prompt3_path = scheme_name+\"_3.txt\"\n",
    "    output_file_path = os.path.join(output_directory, prompt1_path)\n",
    "    with open(output_file_path, 'w+') as output_file:\n",
    "        output_file.write(img_prompt1)\n",
    "\n",
    "    output_file_path = os.path.join(output_directory, prompt2_path)\n",
    "    with open(output_file_path, 'w+') as output_file:\n",
    "        output_file.write(img_prompt2)\n",
    "\n",
    "    output_file_path = os.path.join(output_directory, prompt3_path)\n",
    "    with open(output_file_path, 'w+') as output_file:\n",
    "        output_file.write(img_prompt3)\n",
    "\n",
    "    print(f\"Image prompts for '{file_name}' saved successfully in '{output_directory}'\")\n",
    "\n",
    "\n",
    "# Once the loop finishes, write the results dictionary to a text file\n",
    "results_file_path = \"/content/drive/MyDrive/\" + \"relative path\" + \"results_final.txt\"\n",
    "with open(results_file_path, 'w') as results_file:\n",
    "    results_file.write(str(results))\n",
    "\n",
    "print(f\"Results written to '{results_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to check quality of image prompts\n",
    "#### (Executing the 2 cells below is not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17635,
     "status": "ok",
     "timestamp": 1731255825734,
     "user": {
      "displayName": "PARTH SUDAN",
      "userId": "12683738902671778199"
     },
     "user_tz": -330
    },
    "id": "DY9wCg51wlJj",
    "outputId": "d1d8ded2-abd8-498a-a01f-2584b6ab6f4f"
   },
   "outputs": [],
   "source": [
    "!pip install textstat\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import spacy\n",
    "import textstat\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18312,
     "status": "ok",
     "timestamp": 1731255898921,
     "user": {
      "displayName": "PARTH SUDAN",
      "userId": "12683738902671778199"
     },
     "user_tz": -330
    },
    "id": "5VpdV-Gswrtb",
    "outputId": "9a47f589-36a4-4dcd-f7c1-a14141152d63"
   },
   "outputs": [],
   "source": [
    "# Load a transformer model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def read_prompts(file_paths):\n",
    "    prompts = []\n",
    "    for path in file_paths:\n",
    "        with open(path, \"r\") as file:\n",
    "            prompts.append(file.read().strip())\n",
    "    return prompts\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy().reshape(1, -1)\n",
    "\n",
    "def calculate_cosine_similarity(prompts):\n",
    "    embeddings = [get_embedding(prompt) for prompt in prompts]\n",
    "    sim1 = cosine_similarity(embeddings[0], embeddings[1])\n",
    "    sim2 = cosine_similarity(embeddings[0], embeddings[2])\n",
    "    sim3 = cosine_similarity(embeddings[1], embeddings[2])\n",
    "    all_similarities = np.array([sim1[0][0], sim2[0][0], sim3[0][0]])\n",
    "    avg_similarity = np.mean(all_similarities)\n",
    "    return avg_similarity\n",
    "\n",
    "def calculate_token_lengths(prompts):\n",
    "    return [len(prompt.split()) for prompt in prompts]\n",
    "\n",
    "def calculate_lexical_diversity(prompts):\n",
    "    return [len(set(prompt.split())) / len(prompt.split()) for prompt in prompts]\n",
    "\n",
    "def calculate_readability_scores(prompts):\n",
    "    flesch_scores = [textstat.flesch_reading_ease(prompt) for prompt in prompts]\n",
    "    fog_scores = [textstat.gunning_fog(prompt) for prompt in prompts]\n",
    "    return flesch_scores, fog_scores\n",
    "\n",
    "def evaluate_prompts_for_scheme(scheme_name, file_paths):\n",
    "    prompts = read_prompts(file_paths)\n",
    "\n",
    "    # Consistency metrics\n",
    "    avg_cosine_similarity = calculate_cosine_similarity(prompts)\n",
    "    token_lengths = calculate_token_lengths(prompts)\n",
    "    lexical_diversity = calculate_lexical_diversity(prompts)\n",
    "    flesch_scores, fog_scores = calculate_readability_scores(prompts)\n",
    "\n",
    "    print(f\"Metrics for Scheme: {scheme_name}\")\n",
    "    print(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n",
    "    print(\"Token Lengths:\", token_lengths)\n",
    "    print(\"Lexical Diversity:\", [f\"{diversity:.4f}\" for diversity in lexical_diversity])\n",
    "    print(\"Readability Scores (Flesch Reading Ease):\", flesch_scores)\n",
    "    print(\"Readability Scores (Gunning Fog):\", fog_scores)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "def main(directory_path):\n",
    "    file_paths = glob(os.path.join(directory_path, \"*.txt\"))\n",
    "    scheme_names = set(os.path.basename(f).split('_')[0] for f in file_paths)\n",
    "\n",
    "    for scheme_name in scheme_names:\n",
    "        problem_file = os.path.join(directory_path, f\"{scheme_name}_1.txt\")\n",
    "        application_file = os.path.join(directory_path, f\"{scheme_name}_2.txt\")\n",
    "        impact_file = os.path.join(directory_path, f\"{scheme_name}_3.txt\")\n",
    "\n",
    "        # Check if all three files exist\n",
    "        if os.path.exists(problem_file) and os.path.exists(application_file) and os.path.exists(impact_file):\n",
    "            evaluate_prompts_for_scheme(scheme_name, [problem_file, application_file, impact_file])\n",
    "        else:\n",
    "            print(f\"Warning: Not all prompt files found for scheme '{scheme_name}'.\")\n",
    "\n",
    "# Define the directory where all prompt files are stored\n",
    "directory_path = \"/content/drive/MyDrive/\" + \"remaining path of image prompts\"\n",
    "\n",
    "# Run the evaluation\n",
    "main(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate images using dall-e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 588823,
     "status": "ok",
     "timestamp": 1731242180907,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "50k-VBIoIlxm",
    "outputId": "9ad5342f-c4cf-4b55-f1ac-9cf22ed1d7f8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# Input and output directories\n",
    "input_directory = \"/content/drive/MyDrive/\" + \"remaining path for image prompts\"\n",
    "output_directory = \"/content/drive/MyDrive/\" + \"remaining path for image outputs\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Collect paths of all .txt files in the input directory\n",
    "file_paths = [os.path.join(input_directory, file) for file in os.listdir(input_directory) if file.endswith(\".txt\")]\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "client = OpenAI(api_key='openai_api')\n",
    "\n",
    "# Loop through each file and generate an image\n",
    "for file_path in file_paths:\n",
    "    # Read the file contents as prompt\n",
    "    with open(file_path, 'r') as file:\n",
    "        prompt = file.read().strip()  # Remove any leading/trailing whitespace\n",
    "\n",
    "    # Generate the image\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # Retrieve the image URL from the response\n",
    "    image_url = response.data[0].url\n",
    "\n",
    "    # Download the image and save it to the output directory\n",
    "    image_data = requests.get(image_url).content\n",
    "    image_filename = os.path.splitext(os.path.basename(file_path))[0] + \".png\"\n",
    "    image_path = os.path.join(output_directory, image_filename)\n",
    "\n",
    "    # Save the image\n",
    "    with open(image_path, \"wb\") as image_file:\n",
    "        image_file.write(image_data)\n",
    "\n",
    "    print(f\"Image saved to {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF_KJ6xsYDB0"
   },
   "source": [
    "# Assigment Part 2 - Pipeline\n",
    "## Iterative improvement of image relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30692,
     "status": "ok",
     "timestamp": 1732122750821,
     "user": {
      "displayName": "DHRUV SHRIMALI",
      "userId": "10814109945606918863"
     },
     "user_tz": -330
    },
    "id": "_xTzx-ytYINF",
    "outputId": "f90472a8-c965-45f9-d38d-fb7f49687eb4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cjro9QxnYNHU"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "PROJECT_ID = \"google_cloud_project\"\n",
    "\n",
    "# login using the email ID in the google cloud project\n",
    "auth.authenticate_user(project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to generate better image prompts using previously generated LLM write-up\n",
    "#### (Commented prompt is older prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRXUzE-0YRN5"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"openai_api\")\n",
    "\n",
    "def get_basic_prompts(filename, file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Remove '.txt' from the file name\n",
    "    scheme_name = file_name.replace(\".txt\", \"\")\n",
    "\n",
    "    description_prompt = f\"\"\"Generate a detailed description of all characters, that should be used for creating posters for {scheme_name}.\n",
    "    It should have 2-3 main characters at max. Explicitly write all features describing the outwards appearance of each character.\n",
    "    Also mention the art style of the poster in definite art forms liek realistic, manga, cartoon, etc.\n",
    "    Do not specify background or facial expressions of characters, because that will be determined according to the scene.\n",
    "    Please write only the clear and concise answer.\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that helps in creating image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": description_prompt}\n",
    "        ]\n",
    "    )\n",
    "    description = completion.choices[0].message.content\n",
    "\n",
    "    prompt1 = f\"\"\"\n",
    "        Generate a short image prompt to depict the 'Problem Statement' for the '{scheme_name}':\\n\\n\"\n",
    "        {content}\\n\\n\n",
    "        Instructions:\\n\n",
    "        - Show the main character (e.g., 'Raju the farmer' or 'Shweta the housewife', etc, whatever is more appropriate) experiencing the challenges described in the scheme's problem statement, such as financial struggles or resource shortages, etc.\\n\n",
    "        - Use a rural or village setting with elements like small farms, simple houses, or crops to illustrate the environment, according to the scheme's objective.\\n\n",
    "        - Focus on conveying the difficulties faced by beneficiaries before receiving support, such as worried expressions, sparse resources, or modest living conditions, etc.\n",
    "        ///\n",
    "        {description}\n",
    "        \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt1}\n",
    "        ]\n",
    "    )\n",
    "    img_prompt1 = completion.choices[0].message.content\n",
    "\n",
    "    # prompt2 = f\"\"\"\n",
    "    #     Generate an image prompt to illustrate the 'Application Process' for the '{scheme_name}':\\n\\n\"\n",
    "    #     \"{content}\\n\\n\"\n",
    "    #     \"Instructions:\\n\"\n",
    "    #     \"- Depict a scene showing the enrollment steps, with the main character (e.g., 'Raju the farmer' or 'Shweta the housewife', etc, whatever is more approprite and mentioned later) at a registration desk or using a digital device.\\n\n",
    "    #     \"- Highlight the required documents, such as Aadhaar card, bank passbook, or application forms, as visible elements in the scene.\\n\n",
    "    #     \"- Include a friendly government official or digital interface to emphasize the assistance provided during the application process.\\n\n",
    "    #     \"- Set the scene in a government office or rural setting, focusing on the action of registration and the accessibility of the process.\n",
    "    #     ///\n",
    "    #     {description}\n",
    "    #     ///\n",
    "    #     Here is the previous image prompt, ensure consistency of characters and story:\n",
    "    #     {img_prompt1}\n",
    "    #     \"\"\"\n",
    "    prompt2 = f\"\"\"\n",
    "        Generate a short image prompt to illustrate the 'Application Process' for the '{scheme_name}':\\n\\n\"\n",
    "        \"{content}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Depict a scene showing the enrollment steps, with the main character (e.g., 'Raju the farmer' or 'Shweta the housewife', etc, whatever is more approprite and mentioned later) at a registration desk or using a digital device.\\n\n",
    "        \"- Highlight the required documents, such as Aadhaar card, bank passbook, or application forms, as visible elements in the scene.\\n\n",
    "        \"- Include a friendly government official or digital interface to emphasize the assistance provided during the application process.\\n\n",
    "        \"- Set the scene in a government office or rural setting, focusing on the action of registration and the accessibility of the process.\n",
    "        ///\n",
    "        {description}\n",
    "        \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt2}\n",
    "        ]\n",
    "    )\n",
    "    img_prompt2 = completion.choices[0].message.content\n",
    "\n",
    "    # prompt3 = f\"\"\"\n",
    "    #     Generate an image prompt for the '{scheme_name}':\\n\\n\"\n",
    "    #     f\"{content}\\n\\n\"\n",
    "    #     Instructions:\\n\n",
    "    #     - Use a rural/appropriate setting and portray characters benefiting from a government support scheme.\n",
    "    #     - Include symbols of agricultural aid or community support, illustrating the scheme’s purpose.\n",
    "    #     ///\n",
    "    #     {description}\n",
    "    #     ///\n",
    "    #     Here are the previous prompts, ensure consistency of characters and story:\n",
    "    #     {img_prompt1}\n",
    "    #     {img_prompt2}\n",
    "    #     \"\"\"\n",
    "    prompt3 = f\"\"\"\n",
    "        Generate an short image prompt for the '{scheme_name}':\\n\\n\"\n",
    "        f\"{content}\\n\\n\"\n",
    "        Instructions:\\n\n",
    "        - Use a rural/appropriate setting and portray characters benefiting from a government support scheme.\n",
    "        - Include symbols of agricultural aid or community support, illustrating the scheme’s purpose.\n",
    "        ///\n",
    "        {description}\n",
    "        \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt3}\n",
    "        ]\n",
    "    )\n",
    "    img_prompt3 = completion.choices[0].message.content\n",
    "\n",
    "    return description, img_prompt1, img_prompt2, img_prompt3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code snippet to generate questions about generated images\n",
    "#### PVQ: Prompt Verification Questions (shallower)\n",
    "#### IBQ: Image Based Questions (deeper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1wLzlyrYYD5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"openai_api\")\n",
    "\n",
    "def get_questions(image_prompt):\n",
    "    # Prompt Verification Questions = PVQ\n",
    "    pvq_part1 = f\"\"\"Instruction: Given the following image prompt, generate a set of Prompt Verification Questions (PVQ). These questions should focus on confirming whether the generated image matches the description in the prompt. They should verify key elements like characters, actions, objects, and settings mentioned in the prompt.\n",
    "    Input:\n",
    "    \"\"\"\n",
    "    pvq_part2 = \"\"\"\n",
    "\n",
    "    Output Format:\n",
    "    1. Question\n",
    "    2. Question\n",
    "    3. Question\n",
    "    4. Question\n",
    "    \"\"\"\n",
    "\n",
    "    # Image Based Questions = ibq\n",
    "    ibq_part1 = f\"\"\"Instruction: Given the following image prompt, generate a set of Image-Based Questions (IBQ). These questions should focus on encouraging detailed observation and analysis of the image, covering aspects like specific objects, attire, background elements, or nuanced actions not explicitly stated in the prompt.\n",
    "    Input:\n",
    "    \"\"\"\n",
    "    ibq_part2 = \"\"\"\n",
    "\n",
    "    Output Format:\n",
    "    1. Question\n",
    "    2. Question\n",
    "    3. Question\n",
    "    4. Question\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates helps verify image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": pvq_part1+image_prompt+pvq_part2}\n",
    "        ]\n",
    "    )\n",
    "    pvq = completion.choices[0].message.content\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates helps verify image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": ibq_part1+image_prompt+ibq_part2}\n",
    "        ]\n",
    "    )\n",
    "    ibq = completion.choices[0].message.content\n",
    "    return pvq, ibq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to get image provided the image prompt (dall-e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lMTe-jbYY6V"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = 'openai_api')\n",
    "\n",
    "# original_prompt = new_prompt\n",
    "def get_image(prompt):\n",
    "    response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "    )\n",
    "\n",
    "    image_url = response.data[0].url\n",
    "    return image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code snippet to answer questions about image (gemini-1.5-flash-002)\n",
    "#### Model takes image and questions as input, and answers them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uz1J-0rwYblx"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import traceback\n",
    "\n",
    "# Before using this, you need to authenticate yourself in the terminal, will check in google colab\n",
    "# Replace with your actual project ID\n",
    "PROJECT_ID = \"google_cloud_project\"\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "\n",
    "def interpret_image(image_url, pvq, ibq):\n",
    "    try:\n",
    "        # Send a GET request to download the image\n",
    "        response = requests.get(image_url, timeout=10)  # Add timeout to prevent hanging\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        # Load the image data into a BytesIO object\n",
    "        img_byte_array = io.BytesIO(response.content)\n",
    "\n",
    "        # Open the image with PIL\n",
    "        img = PILImage.open(img_byte_array)\n",
    "\n",
    "        # Convert the image to byte data (JPEG format)\n",
    "        final_img_byte_array = io.BytesIO()\n",
    "        img.save(final_img_byte_array, format='JPEG')\n",
    "        final_img_byte_array = final_img_byte_array.getvalue()\n",
    "\n",
    "        # Create a Part object with the byte data\n",
    "        image_part = Part.from_data(data=final_img_byte_array, mime_type=\"image/jpeg\")\n",
    "\n",
    "        # Initialize the model\n",
    "        model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "\n",
    "        # Generate PVQ response\n",
    "        pvq_response = model.generate_content(\n",
    "            [\n",
    "                image_part,  # Pass the image as a part\n",
    "                pvq,\n",
    "            ]\n",
    "        )\n",
    "        pvq_interpretation = pvq_response.text if hasattr(pvq_response, 'text') else pvq_response\n",
    "\n",
    "        # Generate IBQ response\n",
    "        ibq_response = model.generate_content(\n",
    "            [\n",
    "                image_part,  # Pass the image as a part\n",
    "                ibq,\n",
    "            ]\n",
    "        )\n",
    "        ibq_interpretation = ibq_response.text if hasattr(ibq_response, 'text') else ibq_response\n",
    "\n",
    "        return pvq_interpretation, ibq_interpretation\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for {image_url}: {e}\")\n",
    "        traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_url}: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to refine prompt according to previous prompt and question-answers on generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AC5z2KZeYdqv"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = 'openai_api')\n",
    "\n",
    "def refine_prompt(answer_pvq, answer_ibq, curr_prompt, description):\n",
    "    image_betterment_prompt = f\"\"\"Here is the old image prompt:\n",
    "    {curr_prompt}\n",
    "    And here are the answers to some questions about the image generated by the old:\n",
    "    {answer_pvq}\n",
    "    {answer_ibq}\n",
    "\n",
    "    Using the above information, create a better and more detailed version of the old image prompt, but make it @concise@.\n",
    "    Retain the essence of the original prompt, such as:  'difficulties faced by beneficiaries before receiving support',\n",
    "    'illustration of the application process', or 'characters benefiting from a government support scheme', whichever one\n",
    "    of three was used in the above text. Improve its specificity and richness. Space will be left for the original description\n",
    "    of the characters, and art style, @so do not leave space for it or make the prompt too long@.\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates image generation prompts.\"},\n",
    "            {\"role\": \"user\", \"content\": image_betterment_prompt}\n",
    "        ]\n",
    "    )\n",
    "    better_prompt = completion.choices[0].message.content\n",
    "\n",
    "    Additional_text = f\"\"\"Follow the description given below:\\n {description}\"\"\"\n",
    "\n",
    "    better_prompt = better_prompt + Additional_text\n",
    "    return better_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to improve image prompts iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNrJHbrTYhhT"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Example function to clean the input string (prompt) - helpful to reduce token count\n",
    "def clean_prompt(prompt):\n",
    "    # Remove unnecessary sequences or replace them\n",
    "    prompt = prompt.replace(\"\\\\n\", \"\\n\")  # Removes escape characters\n",
    "    prompt = prompt.replace(\"\\\\\", \"\")  # Removes escape characters\n",
    "    prompt = prompt.replace(\"#\", \"\")  # Removes escape characters\n",
    "    prompt = prompt.replace(\"*\", \"\")  # Removes escape characters\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def iterative_refinement(iters, image_prompt1, image_prompt2, image_prompt3, description):\n",
    "    prompts = {\n",
    "        \"prompt1\": {},\n",
    "        \"prompt2\": {},\n",
    "        \"prompt3\": {},\n",
    "        \"url1\": {},\n",
    "        \"url2\": {},\n",
    "        \"url3\": {}\n",
    "    }\n",
    "\n",
    "    curr_prompt1 = clean_prompt(image_prompt1)\n",
    "    curr_prompt2 = clean_prompt(image_prompt2)\n",
    "    curr_prompt3 = clean_prompt(image_prompt3)\n",
    "\n",
    "    prompts[\"prompt1\"][0] = curr_prompt1\n",
    "    prompts[\"prompt2\"][0] = curr_prompt2\n",
    "    prompts[\"prompt3\"][0] = curr_prompt3\n",
    "\n",
    "    for i in range(1, iters + 1):\n",
    "        # Generate image URLs\n",
    "        url1 = get_image(curr_prompt1)\n",
    "        time.sleep(5)\n",
    "        url2 = get_image(curr_prompt2)\n",
    "        time.sleep(5)\n",
    "        url3 = get_image(curr_prompt3)\n",
    "        time.sleep(5)\n",
    "        print(f\"Got images for prompts in iteration {i-1}\")\n",
    "\n",
    "\n",
    "        prompts[\"url1\"][i-1] = url1\n",
    "        prompts[\"url2\"][i-1] = url2\n",
    "        prompts[\"url3\"][i-1] = url3\n",
    "\n",
    "        # Generate PVQ and IBQ\n",
    "        pvq1, ibq1 = get_questions(curr_prompt1)\n",
    "        time.sleep(5)\n",
    "        pvq2, ibq2 = get_questions(curr_prompt2)\n",
    "        time.sleep(5)\n",
    "        pvq3, ibq3 = get_questions(curr_prompt3)\n",
    "        time.sleep(5)\n",
    "        print(f\"Got image questions in iteration {i}\")\n",
    "\n",
    "        # Interpret the images to get answers\n",
    "        answer_pvq1, answer_ibq1 = interpret_image(url1, pvq1, ibq1)\n",
    "        answer_pvq2, answer_ibq2 = interpret_image(url2, pvq2, ibq2)\n",
    "        answer_pvq3, answer_ibq3 = interpret_image(url3, pvq3, ibq3)\n",
    "        print(f\"Got image answers in iteration {i}\")\n",
    "\n",
    "        # Refine the prompts based on answers\n",
    "        curr_prompt1 = refine_prompt(answer_pvq1, answer_ibq1, curr_prompt1, description)\n",
    "        time.sleep(5)\n",
    "        curr_prompt2 = refine_prompt(answer_pvq2, answer_ibq2, curr_prompt2, description)\n",
    "        time.sleep(5)\n",
    "        curr_prompt3 = refine_prompt(answer_pvq3, answer_ibq3, curr_prompt3, description)\n",
    "        time.sleep(5)\n",
    "        print(f\"Refined prompts in iteration {i}\")\n",
    "        print()\n",
    "\n",
    "        # Clean prompts\n",
    "        curr_prompt1 = clean_prompt(curr_prompt1)\n",
    "        curr_prompt2 = clean_prompt(curr_prompt2)\n",
    "        curr_prompt3 = clean_prompt(curr_prompt3)\n",
    "\n",
    "        # Store current prompts for this iteration\n",
    "        prompts[\"prompt1\"][i] = curr_prompt1\n",
    "        prompts[\"prompt2\"][i] = curr_prompt2\n",
    "        prompts[\"prompt3\"][i] = curr_prompt3\n",
    "\n",
    "\n",
    "    # Generate final image URLs\n",
    "    url1 = get_image(curr_prompt1)\n",
    "    time.sleep(5)\n",
    "    url2 = get_image(curr_prompt2)\n",
    "    time.sleep(5)\n",
    "    url3 = get_image(curr_prompt3)\n",
    "    time.sleep(5)\n",
    "    print(f\"Got images for prompts in iteration {iters}\")\n",
    "\n",
    "    prompts[\"url1\"][iters] = url1\n",
    "    prompts[\"url2\"][iters] = url2\n",
    "    prompts[\"url3\"][iters] = url3\n",
    "\n",
    "\n",
    "    return prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to save all images and prompts generated during iterative prompt refinement to track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0znqjvDZcUO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def save_experiment_images(total_iters, prompts, scheme_name):\n",
    "    # Create the experiment directory\n",
    "    exp_dir = \"/content/drive/MyDrive/\" + \"relative path for saving all intermediate images\" + scheme_name\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over each iteration\n",
    "    for i in range(total_iters + 1):\n",
    "        # Create iteration-specific subdirectory\n",
    "        iter_dir = os.path.join(exp_dir, f\"Iter{i}\")\n",
    "        os.makedirs(iter_dir, exist_ok=True)\n",
    "\n",
    "        # Save images for each prompt\n",
    "        for j in range(1, 4):  # Assuming 3 prompts\n",
    "            image_url = prompts[f'url{j}'][i]\n",
    "            image_path = os.path.join(iter_dir, f\"image{j}.jpg\")\n",
    "\n",
    "            try:\n",
    "                # Download the image from the URL\n",
    "                response = requests.get(image_url, stream=True)\n",
    "                if response.status_code == 200:\n",
    "                    # Save the image to the corresponding path\n",
    "                    with open(image_path, 'wb') as file:\n",
    "                        file.write(response.content)\n",
    "                else:\n",
    "                    print(f\"Failed to download image from {image_url}. HTTP status: {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading image from {image_url}: {e}\")\n",
    "\n",
    "    print('Images saved succesfully')\n",
    "\n",
    "\n",
    "def save_final_prompts(TOTAL_ITERS, prompts, scheme_name):\n",
    "    # Create the experiment directory\n",
    "    exp_dir = \"/content/drive/MyDrive/\" + \"relative path for saving final prompts\" + scheme_name\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    prompt1 = prompts[\"prompt1\"][TOTAL_ITERS]\n",
    "    prompt2 = prompts[\"prompt2\"][TOTAL_ITERS]\n",
    "    prompt3 = prompts[\"prompt3\"][TOTAL_ITERS]\n",
    "\n",
    "    file_path1 = os.path.join(exp_dir, f\"{scheme_name}-1.txt\")\n",
    "    with open(file_path1, 'w+') as file:\n",
    "        file.write(prompt1)\n",
    "\n",
    "    file_path2 = os.path.join(exp_dir, f\"{scheme_name}-2.txt\")\n",
    "    with open(file_path2, 'w+') as file:\n",
    "        file.write(prompt2)\n",
    "\n",
    "    file_path3 = os.path.join(exp_dir, f\"{scheme_name}-3.txt\")\n",
    "    with open(file_path3, 'w+') as file:\n",
    "        file.write(prompt3)\n",
    "\n",
    "    print('Prompt saved succesfully')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to save all intermediate prompts in a json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj4toNxKNMcm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_all_prompts(prompts, scheme_name):\n",
    "    experiment_data = {\n",
    "        \"scheme_name\": scheme_name,\n",
    "        \"prompts\": prompts\n",
    "    }\n",
    "    # Write the data to a JSON file\n",
    "    file_name = \"/content/drive/MyDrive/\" + \"relative path for saving all prompts\" + scheme_name +\".json\"\n",
    "    with open(file_name, \"w+\") as f:\n",
    "        json.dump(experiment_data, f, indent=4)\n",
    "    print(f\"Prompts saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3-lXtUItp8T"
   },
   "source": [
    "## Main function to iteratively refine images for all welfare schemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmujaJxSUlO1",
    "outputId": "323271a4-9548-4fb2-b1ee-c258e8af90d3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "output_directory = \"/content/drive/MyDrive/\" + \"remaining path to folder to save final images\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "directory = \"/content/drive/MyDrive/\" + \"remaining path for outputs for LLM write-ups\"\n",
    "\n",
    "file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".txt\")]\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Remove '.txt' from the file name\n",
    "    file_name = os.path.basename(file_path)\n",
    "    scheme_name = file_name.replace(\".txt\", \"\")\n",
    "    description, image_prompt1, image_prompt2, image_prompt3 = get_basic_prompts(file_name, file_path)\n",
    "\n",
    "    # print(f'\\nOriginal description:\\n {description}\\n\\n')\n",
    "\n",
    "    # Hyperparameter\n",
    "    TOTAL_ITERS = 4\n",
    "\n",
    "    print(f\"Iterating through prompts for {scheme_name}\")\n",
    "    try:\n",
    "        prompts = iterative_refinement(TOTAL_ITERS, image_prompt1, image_prompt2, image_prompt3, description)\n",
    "        print('\\n')\n",
    "        time.sleep(10)\n",
    "\n",
    "    except Exception as e:\n",
    "        #Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an API Error: {e} for {scheme_name}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    better_prompt1 = prompts[\"prompt1\"][TOTAL_ITERS]\n",
    "    better_prompt2 = prompts[\"prompt2\"][TOTAL_ITERS]\n",
    "    better_prompt3 = prompts[\"prompt3\"][TOTAL_ITERS]\n",
    "\n",
    "    results.append({\n",
    "        'scheme_name': scheme_name,\n",
    "        'prompt1': better_prompt1,\n",
    "        'prompt2': better_prompt2,\n",
    "        'prompt3': better_prompt3\n",
    "    })\n",
    "\n",
    "    # Print all prompts across iterations\n",
    "    # print(\"\\nAll prompts across iterations:\")\n",
    "    # for i in range(0, TOTAL_ITERS + 1):\n",
    "    #     print(f\"Iteration {i}:\")\n",
    "    #     print(f\"  Prompt 1: {prompts['prompt1'][i]}\")\n",
    "    #     print(f\"  Prompt 2: {prompts['prompt2'][i]}\")\n",
    "    #     print(f\"  Prompt 3: {prompts['prompt3'][i]}\")\n",
    "    #     print('-'* 80)\n",
    "    #     print('')\n",
    "\n",
    "\n",
    "    # Print all prompts across iterations\n",
    "    # print(\"\\n\\nAll links across iterations:\")\n",
    "    # for i in range(0, TOTAL_ITERS + 1):\n",
    "    #     print(f\"Iteration {i}:\")\n",
    "    #     print(f\"  Link 1: {prompts['url1'][i]}\")\n",
    "    #     print(f\"  Link 2: {prompts['url2'][i]}\")\n",
    "    #     print(f\"  Link 3: {prompts['url3'][i]}\")\n",
    "    #     print('-'* 80)\n",
    "    #     print('')\n",
    "\n",
    "    save_experiment_images(TOTAL_ITERS, prompts, scheme_name)\n",
    "    save_final_prompts(TOTAL_ITERS, prompts, scheme_name)\n",
    "    save_all_prompts(prompts, scheme_name)\n",
    "\n",
    "    for j in range(1, 4):\n",
    "        image_url = prompts[f'url{j}'][TOTAL_ITERS]\n",
    "        image_path = os.path.join(output_directory, f\"{scheme_name}_{j}.jpg\")\n",
    "        try:\n",
    "            # Download the image from the URL\n",
    "            response = requests.get(image_url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                # Save the image to the corresponding path\n",
    "                with open(image_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print(f\"Failed to download image from {image_url}. HTTP status: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image from {image_url}: {e}\")\n",
    "\n",
    "\n",
    "# Once the loop finishes, write the results dictionary to a text file\n",
    "results_file_path = \"/content/drive/MyDrive/\" + \"relative path\" + \"results_2.txt\"\n",
    "with open(results_file_path, 'w+') as results_file:\n",
    "    results_file.write(str(results))\n",
    "\n",
    "print(f\"Results written to '{results_file_path}'\")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print execution time\n",
    "execution_time = end_time - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)  # Converts to minutes and seconds\n",
    "print(f\"Execution Time: {int(minutes)} minutes and {seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdbqppXL39Yk"
   },
   "source": [
    "### Code to check quality of image prompts\n",
    "#### (Executing the cell below is not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLoSjipkx97A"
   },
   "outputs": [],
   "source": [
    "!pip install textstat\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import textstat\n",
    "from glob import glob\n",
    "\n",
    "# Load a transformer model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def read_prompts_from_json(file_path):\n",
    "    \"\"\"Reads prompts from a JSON file, ignoring URL entries.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract all iterations of prompts1, prompts2, prompts3\n",
    "    prompts = []\n",
    "    for prompt_key in [\"prompt1\", \"prompt2\", \"prompt3\"]:\n",
    "        if prompt_key in data[\"prompts\"]:\n",
    "            iterations = data[\"prompts\"][prompt_key]\n",
    "            for iteration in sorted(iterations.keys(), key=lambda x: int(x)):  # Sort by numeric keys\n",
    "                prompts.append(iterations[iteration])\n",
    "    return prompts\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy().reshape(1, -1)\n",
    "\n",
    "def calculate_cosine_similarity(prompts):\n",
    "    embeddings = [get_embedding(prompt) for prompt in prompts]\n",
    "    similarities = []\n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            similarities.append(cosine_similarity(embeddings[i], embeddings[j])[0][0])\n",
    "    avg_similarity = np.mean(similarities) if similarities else 0\n",
    "    return avg_similarity\n",
    "\n",
    "def calculate_token_lengths(prompts):\n",
    "    return [len(prompt.split()) for prompt in prompts]\n",
    "\n",
    "def calculate_lexical_diversity(prompts):\n",
    "    return [len(set(prompt.split())) / len(prompt.split()) for prompt in prompts]\n",
    "\n",
    "def calculate_readability_scores(prompts):\n",
    "    flesch_scores = [textstat.flesch_reading_ease(prompt) for prompt in prompts]\n",
    "    fog_scores = [textstat.gunning_fog(prompt) for prompt in prompts]\n",
    "    return flesch_scores, fog_scores\n",
    "\n",
    "def evaluate_prompts_for_scheme(scheme_name, file_path):\n",
    "    prompts = read_prompts_from_json(file_path)\n",
    "\n",
    "    # Consistency metrics\n",
    "    avg_cosine_similarity = calculate_cosine_similarity(prompts)\n",
    "    token_lengths = calculate_token_lengths(prompts)\n",
    "    lexical_diversity = calculate_lexical_diversity(prompts)\n",
    "    flesch_scores, fog_scores = calculate_readability_scores(prompts)\n",
    "\n",
    "    # Display metrics for the scheme\n",
    "    print(f\"Metrics for Scheme: {scheme_name}\")\n",
    "    print(f\"Average Cosine Similarity: {avg_cosine_similarity:.4f}\")\n",
    "    print(\"Token Lengths:\", token_lengths)\n",
    "    print(\"Lexical Diversity:\", [f\"{diversity:.4f}\" for diversity in lexical_diversity])\n",
    "    print(\"Readability Scores (Flesch Reading Ease):\", flesch_scores)\n",
    "    print(\"Readability Scores (Gunning Fog):\", fog_scores)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "def main(directory_path):\n",
    "    # Find all JSON files in the directory\n",
    "    file_paths = glob(os.path.join(directory_path, \"*.json\"))\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        # Extract the scheme name from the filename (excluding extension)\n",
    "        scheme_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        evaluate_prompts_for_scheme(scheme_name, file_path)\n",
    "\n",
    "# Define the directory where all prompt files are stored\n",
    "directory_path = \"/content/drive/MyDrive/\" + \"remaining path of the new image prompts\"\n",
    "\n",
    "# Run the evaluation\n",
    "main(directory_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
